{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/envs/ampligraph/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from ampligraph.latent_features import ComplEx, save_model, restore_model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate, cross_val_predict\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier    \n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, cohen_kappa_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Loading triplets and labels for training and test sets used for embedding\n",
    "trainData = np.load(\"dev/trainDev.npy\")\n",
    "testData = np.load(\"dev/valid.npy\")\n",
    "Y_train = trainData[:,-1].astype(float)\n",
    "Y_test = testData[:,-1].astype(float)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-17 10:39:37,083 - gensim.utils - INFO - loading Word2VecKeyedVectors object from ./dev/RDF2VECModels/RDF2Vec_sg_WalksData-2_300_10_8_1neg_wv\n",
      "2019-06-17 10:39:37,200 - gensim.utils - INFO - setting ignored attribute vectors_norm to None\n",
      "2019-06-17 10:39:37,202 - gensim.utils - INFO - loaded ./dev/RDF2VECModels/RDF2Vec_sg_WalksData-2_300_10_8_1neg_wv\n",
      "2019-06-17 10:39:37,202 - gensim.utils - INFO - loading Word2VecKeyedVectors object from ./dev/RDF2VECModels/RDF2Vec_sg_WalksData-2_150_10_8_10neg_wv\n",
      "2019-06-17 10:39:37,271 - gensim.utils - INFO - setting ignored attribute vectors_norm to None\n",
      "2019-06-17 10:39:37,272 - gensim.utils - INFO - loaded ./dev/RDF2VECModels/RDF2Vec_sg_WalksData-2_150_10_8_10neg_wv\n",
      "2019-06-17 10:39:37,273 - gensim.utils - INFO - loading Word2VecKeyedVectors object from ./dev/RDF2VECModels/RDF2Vec_sg_WalksData-2_300_10_8_10neg_wv\n",
      "2019-06-17 10:39:37,390 - gensim.utils - INFO - setting ignored attribute vectors_norm to None\n",
      "2019-06-17 10:39:37,391 - gensim.utils - INFO - loaded ./dev/RDF2VECModels/RDF2Vec_sg_WalksData-2_300_10_8_10neg_wv\n",
      "2019-06-17 10:39:37,392 - gensim.utils - INFO - loading Word2VecKeyedVectors object from ./dev/RDF2VECModels/RDF2Vec_sg_WalksData-2_150_10_8_1neg_wv\n",
      "2019-06-17 10:39:37,462 - gensim.utils - INFO - setting ignored attribute vectors_norm to None\n",
      "2019-06-17 10:39:37,463 - gensim.utils - INFO - loaded ./dev/RDF2VECModels/RDF2Vec_sg_WalksData-2_150_10_8_1neg_wv\n",
      "2019-06-17 10:39:37,464 - gensim.utils - INFO - loading Word2VecKeyedVectors object from ./dev/RDF2VECModels/RDF2Vec_sg_WalksData_300_200_8_wv\n",
      "2019-06-17 10:39:37,661 - gensim.utils - INFO - setting ignored attribute vectors_norm to None\n",
      "2019-06-17 10:39:37,662 - gensim.utils - INFO - loaded ./dev/RDF2VECModels/RDF2Vec_sg_WalksData_300_200_8_wv\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "models = []\n",
    "models_names = []\n",
    "\n",
    "# DIRECTORIES NAME OF EMBEDDING MODELS\n",
    "ampligraph_models_dn = \"./dev/ampligraphModels\"\n",
    "RDF2VEC_models_dn = \"./dev/RDF2VECModels\"\n",
    "\n",
    "# Load Ampligraph model\n",
    "for fname in os.listdir(ampligraph_models_dn):\n",
    "    models_names.append(fname)\n",
    "    models.append(restore_model(os.path.join(ampligraph_models_dn,fname)))\n",
    "    \n",
    "#Load RDF2VEC models\n",
    "for fname in os.listdir(RDF2VEC_models_dn):\n",
    "    models_names.append(fname)\n",
    "    models.append(KeyedVectors.load(os.path.join(RDF2VEC_models_dn,fname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert triplets to embedding model transR from json dict mapping\n",
    "def triplets_to_vec_TransR(triplets_arr, model_ents, model_rels):\n",
    "    X = []\n",
    "    for triplet in triplets_arr:\n",
    "        s,p,o = triplet[:-1]\n",
    "        # the URIS in the dict does not have chevrons\n",
    "        es = model_ents[s[1:-1]]\n",
    "        ep = model_rels[p[1:-1]]\n",
    "        eo = model_ents[o[1:-1]]\n",
    "        embedding = np.concatenate((es, ep, eo)).flatten()\n",
    "        X.append(embedding)\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert triplets from numpy array into embedding space of model (to apply ML models), for RDF2VEC model\n",
    "def triplets_to_vec_RDF2VEC(triplets_arr, model):\n",
    "    X = []\n",
    "    for triplet in triplets_arr:\n",
    "        s,p,o = triplet[:-1]\n",
    "        es = model.get_vector(s)\n",
    "        ep = model.get_vector(p)\n",
    "        eo = model.get_vector(o)\n",
    "        embedding = np.concatenate((es, ep, eo)).flatten()\n",
    "        X.append(embedding)\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "# Same for ampligraph models\n",
    "def triplets_to_vec_Ampligraph(triplets_arr, model):\n",
    "    X = []\n",
    "    for triplet in triplets_arr:\n",
    "        s,p,o = triplet[:-1]\n",
    "        eso = model.get_embeddings([s,o], type='entity')\n",
    "        ep = model.get_embeddings([p], type='relation')\n",
    "        embedding = np.concatenate((eso,ep)).flatten()\n",
    "#         print(eso.shape)\n",
    "#         print(ep.shape)\n",
    "#         print(embedding.shape)\n",
    "        X.append(embedding)\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HolE_150_200_1', 'ComplEx_150_200_1', 'TransE_150_200_1', 'DistMult_150_200_1', 'RDF2Vec_sg_WalksData-2_300_10_8_1neg_wv', 'RDF2Vec_sg_WalksData-2_150_10_8_10neg_wv', 'RDF2Vec_sg_WalksData-2_300_10_8_10neg_wv', 'RDF2Vec_sg_WalksData-2_150_10_8_1neg_wv', 'RDF2Vec_sg_WalksData_300_200_8_wv']\n"
     ]
    }
   ],
   "source": [
    "print(models_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric data of all models for Hold Out Scheme\n",
    "all_Xtrain = []\n",
    "all_Xtest = []\n",
    "for mod,name in zip(models, models_names):\n",
    "    # RDF2VEC models\n",
    "    if \"RDF2Vec\" in name:\n",
    "        X_train = triplets_to_vec_RDF2VEC(trainData, mod).astype(float)\n",
    "        X_test = triplets_to_vec_RDF2VEC(testData, mod).astype(float)\n",
    "    # Ampligraph models\n",
    "    else:\n",
    "        X_train = triplets_to_vec_Ampligraph(trainData, mod).astype(float)\n",
    "        #print(name)\n",
    "        #print(X_train.shape)\n",
    "        X_test = triplets_to_vec_Ampligraph(testData, mod).astype(float)\n",
    "    all_Xtrain.append(X_train)\n",
    "    all_Xtest.append(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out Scheme\n",
    "def run_classifiers_HO(clfs,Xtrain,Ytrain, Xtest, Ytest, name):\n",
    "    scoring = ['accuracy', \"roc_auc\"]\n",
    "    fieldnames = ['Algorithm', 'AUC', \"Accuracy\", \"Time\"]\n",
    "    \n",
    "    # write header of csv result file\n",
    "#     with open('./results/' + name + \".csv\", 'w', newline='') as csvfile:\n",
    "#         writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "    # Classifiers loop\n",
    "    for i in clfs:\n",
    "        try:\n",
    "            clf = clfs[i]\n",
    "            print(\"\\n\\n======= {0} =======\".format(i))\n",
    "            start = time.time()\n",
    "            clf.fit(Xtrain, Ytrain)\n",
    "            end = time.time()\n",
    "            timing = end - start\n",
    "            y_pred = clf.predict(Xtest)\n",
    "            auc = roc_auc_score(Ytest, y_pred)\n",
    "            acc = accuracy_score(Ytest, y_pred)\n",
    "            \n",
    "            print(\"execution time : \", timing)\n",
    "            print(\"AUC : \", auc)\n",
    "            print(\"accuracy : \", acc)\n",
    "            \n",
    "            results = {\"Algorithm\" : i, \"Time\": timing, \"Accuracy\": acc, \"AUC\": auc}\n",
    "            \n",
    "            # Write result in file\n",
    "#             with open('./results/' + name + \".csv\", 'w', newline='') as csvfile:\n",
    "#                 writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#                 writer.writerow(results)\n",
    "            \n",
    "            # Saving results to file\n",
    "#             w = csv.writer(open(\"./results/\" + name + \"_\" + i + \".csv\", \"w\"))\n",
    "#             for key, val in results.items():\n",
    "#                 w.writerow([key, val])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs_best = {\n",
    "'RF': RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=-1),\n",
    "'MLP': MLPClassifier(solver='adam',alpha=1e-4,hidden_layer_sizes=(300,100),random_state=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      ">>>>>>>>>>>> HolE_150_200_1 <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  11.990300416946411\n",
      "AUC :  0.8567827460677245\n",
      "accuracy :  0.8594115680374457\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  49.17029547691345\n",
      "AUC :  0.8277663301050897\n",
      "accuracy :  0.839518555667001\n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>>>>> ComplEx_150_200_1 <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  14.143194437026978\n",
      "AUC :  0.8550257572635482\n",
      "accuracy :  0.8555667001003009\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  51.9817271232605\n",
      "AUC :  0.8250504842365547\n",
      "accuracy :  0.8254764292878636\n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>>>>> TransE_150_200_1 <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  6.384512901306152\n",
      "AUC :  0.8482344254413077\n",
      "accuracy :  0.8453694416583083\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  46.03837180137634\n",
      "AUC :  0.823463149941617\n",
      "accuracy :  0.8263122701437646\n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>>>>> DistMult_150_200_1 <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  9.326711416244507\n",
      "AUC :  0.8579387320557731\n",
      "accuracy :  0.8594115680374457\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  34.55751180648804\n",
      "AUC :  0.8210217047874167\n",
      "accuracy :  0.8321631561350719\n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>>>>> RDF2Vec_sg_WalksData-2_300_10_8_1neg_wv <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  9.638672113418579\n",
      "AUC :  0.8697304073081943\n",
      "accuracy :  0.8729521899030425\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  45.35594153404236\n",
      "AUC :  0.8771055704375301\n",
      "accuracy :  0.8803075894349716\n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>>>>> RDF2Vec_sg_WalksData-2_150_10_8_10neg_wv <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  5.968363523483276\n",
      "AUC :  0.8644079263685692\n",
      "accuracy :  0.866934135740555\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  24.673535585403442\n",
      "AUC :  0.860137028642077\n",
      "accuracy :  0.8560682046138415\n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>>>>> RDF2Vec_sg_WalksData-2_300_10_8_10neg_wv <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  9.233404397964478\n",
      "AUC :  0.8632069510268563\n",
      "accuracy :  0.8647609495152123\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  36.78895378112793\n",
      "AUC :  0.8652620372278315\n",
      "accuracy :  0.8619190906051488\n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>>>>> RDF2Vec_sg_WalksData-2_150_10_8_1neg_wv <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  6.372180700302124\n",
      "AUC :  0.8697032763239233\n",
      "accuracy :  0.872617853560682\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  32.19673943519592\n",
      "AUC :  0.8789175080706093\n",
      "accuracy :  0.8799732530926112\n",
      "\n",
      "\n",
      "\n",
      ">>>>>>>>>>>> RDF2Vec_sg_WalksData_300_200_8_wv <<<<<<<<<<<<\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  8.199947118759155\n",
      "AUC :  0.8606889209423725\n",
      "accuracy :  0.861250417920428\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  20.9883451461792\n",
      "AUC :  0.8346033381413558\n",
      "accuracy :  0.8470411233701103\n"
     ]
    }
   ],
   "source": [
    "# Hold out scheme\n",
    "for i in range(len(all_Xtrain)):\n",
    "    print(\"\\n\\n\\n>>>>>>>>>>>> {0} <<<<<<<<<<<<\".format(models_names[i]))\n",
    "    run_classifiers_HO(clfs_best, all_Xtrain[i], Y_train, all_Xtest[i], Y_test, models_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSR model\n",
    "# Load TransR model (07/06/19)\n",
    "TransR_model_ents = \"dev/transRmodel/entities_to_embeddings.json\"\n",
    "TransR_model_rels = \"dev/transRmodel/relations_to_embeddings.json\"\n",
    "\n",
    "model_TransR_ents = json.load(open(TransR_model_ents))\n",
    "model_TransR_rels = json.load(open(TransR_model_rels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transR = triplets_to_vec_TransR(trainData, model_TransR_ents, model_TransR_rels)\n",
    "X_test_transR = triplets_to_vec_TransR(testData, model_TransR_ents, model_TransR_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n",
      "execution time :  6.051275253295898\n",
      "AUC :  0.8319788447008722\n",
      "accuracy :  0.8276496155132063\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "execution time :  22.464711904525757\n",
      "AUC :  0.7549814547702453\n",
      "accuracy :  0.7587763289869609\n"
     ]
    }
   ],
   "source": [
    "run_classifiers_HO(clfs_best, X_train_transR, Y_train, X_test_transR, Y_test, \"TransR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
