{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from ampligraph.latent_features import ComplEx, save_model, restore_model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate, cross_val_predict\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier    \n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, cohen_kappa_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# CLASSIFICATION OF THE NEWLY RELEASED TEST SET, WITH THE TRAINING OF THE FULL TRAIN DATA SET\n",
    "# (25k statements with duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading triplets and labels\n",
    "trainData = np.load(\"test/train.npy\")\n",
    "Y = trainData[:,-1]\n",
    "Y = Y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23928, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all test triplets\n",
    "testData = np.load(\"test/test.npy\")\n",
    "testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-17 11:55:55,483 - gensim.utils - INFO - loading Word2VecKeyedVectors object from test/RDF2VECModels/RDF2Vec_sg_fulldata-2_300_10_8_wv\n",
      "2019-06-17 11:55:56,104 - gensim.utils - INFO - setting ignored attribute vectors_norm to None\n",
      "2019-06-17 11:55:56,105 - gensim.utils - INFO - loaded test/RDF2VECModels/RDF2Vec_sg_fulldata-2_300_10_8_wv\n",
      "2019-06-17 11:55:56,106 - gensim.utils - INFO - loading Word2VecKeyedVectors object from test/RDF2VECModels/RDF2Vec_sg_fulldata-2_150_10_8_wv\n",
      "2019-06-17 11:55:56,320 - gensim.utils - INFO - setting ignored attribute vectors_norm to None\n",
      "2019-06-17 11:55:56,322 - gensim.utils - INFO - loaded test/RDF2VECModels/RDF2Vec_sg_fulldata-2_150_10_8_wv\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "models = []\n",
    "models_names = []\n",
    "RDF2VEC_models_dn = \"test/RDF2VECModels\"\n",
    "#RDF2VEC_models_dn = \"./RDF2VEC/fulldata-20epochs\"\n",
    "#RDF2VEC_models_dn = \"./RDF2VEC/fulldata-200dims\"\n",
    "\n",
    "# Load Ampligraph model\n",
    "# for fname in os.listdir(ampligraph_models_dn):\n",
    "#     models_names.append(fname)\n",
    "#     models.append(restore_model(os.path.join(ampligraph_models_dn,fname)))\n",
    "    \n",
    "#Load RDF2VEC models\n",
    "for fname in os.listdir(RDF2VEC_models_dn):\n",
    "    models_names.append(fname)\n",
    "    models.append(KeyedVectors.load(os.path.join(RDF2VEC_models_dn,fname)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert triplets from numpy array into embedding space of model (to apply ML models), for RDF2VEC model\n",
    "def triplets_to_vec_RDF2VEC(triplets_arr, model):\n",
    "    X = []\n",
    "    for triplet in triplets_arr:\n",
    "        s,p,o = triplet[:-1]\n",
    "        es = model.get_vector(s)\n",
    "        ep = model.get_vector(p)\n",
    "        eo = model.get_vector(o)\n",
    "        embedding = np.concatenate((es, ep, eo)).flatten()\n",
    "        X.append(embedding)\n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "# Same for ampligraph models\n",
    "def triplets_to_vec_Ampligraph(triplets_arr, model):\n",
    "    X = []\n",
    "    for triplet in triplets_arr:\n",
    "        s,p,o = triplet[:-1]\n",
    "        eso = model.get_embeddings([s,o], type='entity')\n",
    "        ep = model.get_embeddings([p], type='relation')\n",
    "        embedding = np.concatenate((eso,ep)).flatten()\n",
    "        X.append(embedding)\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RDF2Vec_sg_fulldata-2_300_10_8_wv', 'RDF2Vec_sg_fulldata-2_150_10_8_wv']\n"
     ]
    }
   ],
   "source": [
    "print(models_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric data of all models for Hold Out Scheme\n",
    "all_Xtrain = []\n",
    "all_Xtest = []\n",
    "for mod,name in zip(models, models_names):\n",
    "    # RDF2VEC models\n",
    "    if \"RDF2Vec\" in name:\n",
    "        X_train = triplets_to_vec_RDF2VEC(trainData, mod).astype(float)\n",
    "        X_test = triplets_to_vec_RDF2VEC(testData, mod).astype(float)\n",
    "    # Ampligraph models\n",
    "    else:\n",
    "        X_train = triplets_to_vec_Ampligraph(trainData, mod).astype(float)\n",
    "        X_test = triplets_to_vec_Ampligraph(testData, mod).astype(float)\n",
    "    all_Xtrain.append(X_train)\n",
    "    all_Xtest.append(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export prediction of statements in the challenge format\n",
    "def export_results(y_pred, data, fn):\n",
    "    output = \"\"\n",
    "    for score, statement in zip(y_pred, data):\n",
    "        line = statement + \" <http://swc2017.aksw.org/hasTruthValue> \" + \"\\\"\" + str(score) + \"\\\"^^<http://www.w3.org/2001/XMLSchema#double> .\\n\"\n",
    "        output = output + line\n",
    "    with open(fn, \"w\") as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MLP CLASSIFIER, after param search on valid set\n",
    "mlp_best = MLPClassifier(solver='adam', alpha=0.0001, hidden_layer_sizes=(300,100),random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(300, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_best.fit(all_Xtrain[0], Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_TEST = mlp_best.predict_proba(all_Xtest[0])\n",
    "export_results(y_pred_TEST[:,1], testData[:,3], \"Results_MLPbest_rdf2vec_300_10_8.nt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
